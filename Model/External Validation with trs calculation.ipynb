{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External validation using cross-validated CNN ensemble\n",
    "# Purpose:\n",
    "# 1. Load the ensemble of 5 CV-trained models\n",
    "# 2. Predict TRS scores on an independent CRLM validation cohort\n",
    "# 3. Evaluate performance and produce a detailed report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- External validation of CRLM dataset using cross-validated ensemble models ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401745bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 0: Global settings ---\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"--- Random seed set to 42 ---\")\n",
    "\n",
    "# Set fonts (include Chinese font fallback if needed)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: File paths ---\n",
    "print(\"\\n--- Step 1: Configure file paths ---\")\n",
    "\n",
    "BASE_DIR = \"D:/结直肠癌肝转移Biomarker 诊断/新的策略/Autoencoder\"\n",
    "\n",
    "# Cross-validation model output paths\n",
    "CV_OUTPUT_DIR = \"D:/temp_output_cv\"  # cross-validation root output\n",
    "ENSEMBLE_MODEL_DIR = os.path.join(CV_OUTPUT_DIR, \"ensemble_models\")  # directory containing 5 models\n",
    "\n",
    "# Validation data path\n",
    "VALIDATION_DATA_DIR = os.path.join(BASE_DIR, \"validation_datasets\")\n",
    "\n",
    "# Results output path\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"crlm_validation_with_cv_model\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Input file paths\n",
    "CV_LABEL_ENCODER_FILE = os.path.join(ENSEMBLE_MODEL_DIR, \"label_encoder.pkl\")\n",
    "CV_GENES_FILE = os.path.join(CV_OUTPUT_DIR, \"used_functional_genes_cv.txt\")\n",
    "CRLM_DATA_FILE = os.path.join(VALIDATION_DATA_DIR, \"dat_crlm.csv\")\n",
    "\n",
    "print(f\"Ensemble model directory: {ENSEMBLE_MODEL_DIR}\")\n",
    "print(f\"CRLM validation data: {CRLM_DATA_FILE}\")\n",
    "print(f\"Results output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Check existence\n",
    "required_files = [CV_LABEL_ENCODER_FILE, CV_GENES_FILE, CRLM_DATA_FILE]\n",
    "if not os.path.exists(ENSEMBLE_MODEL_DIR):\n",
    "    print(f\"ERROR: Ensemble model directory not found: {ENSEMBLE_MODEL_DIR}\")\n",
    "    print(\"Please run the cross-validation training script to generate the model files.\")\n",
    "else:\n",
    "    print(\"Ensemble model directory exists.\")\n",
    "\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing_files:\n",
    "    print(\"ERROR: The following required files are missing:\")\n",
    "    for f in missing_files:\n",
    "        print(f\"  - {f}\")\n",
    "    print(\"Please check the paths or re-run the training script.\")\n",
    "else:\n",
    "    print(\"All required files are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Load ensemble models and preprocessors ---\n",
    "print(\"\\n--- Step 2: Load ensemble models and associated preprocessors ---\")\n",
    "\n",
    "try:\n",
    "    models = []\n",
    "    scalers = []\n",
    "    print(\"Loading models:\")\n",
    "    for i in range(1, 6):\n",
    "        model_path = os.path.join(ENSEMBLE_MODEL_DIR, f\"model_fold{i}.keras\")\n",
    "        scaler_path = os.path.join(ENSEMBLE_MODEL_DIR, f\"scaler_fold{i}.pkl\")\n",
    "        if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "            raise FileNotFoundError(f\"Model or scaler for fold {i} not found: {model_path} or {scaler_path}\")\n",
    "        models.append(tf.keras.models.load_model(model_path))\n",
    "        scalers.append(joblib.load(scaler_path))\n",
    "        print(f\"  - Loaded model and scaler for fold {i}\")\n",
    "\n",
    "    print(f\"Loaded {len(models)} cross-validation models successfully.\")\n",
    "\n",
    "    # Load label encoder\n",
    "    cv_label_encoder = joblib.load(CV_LABEL_ENCODER_FILE)\n",
    "    print(\"Label encoder loaded successfully.\")\n",
    "\n",
    "    # Load gene list used for modeling\n",
    "    with open(CV_GENES_FILE, 'r') as f:\n",
    "        cv_model_genes = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    print(f\"Functional gene list loaded: {len(cv_model_genes)} genes\")\n",
    "\n",
    "    print(f\"Model input shape: {models[0].input_shape}\")\n",
    "    print(f\"Label classes: {cv_label_encoder.classes_}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to load models or resources: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48934323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Load and preprocess CRLM validation data ---\n",
    "print(\"\\n--- Step 3: Load and preprocess CRLM validation data ---\")\n",
    "\n",
    "crlm_data = pd.read_csv(CRLM_DATA_FILE, index_col=0)\n",
    "print(f\"CRLM data shape: {crlm_data.shape}\")\n",
    "\n",
    "# Check label column\n",
    "label_col = 'status'\n",
    "if label_col not in crlm_data.columns:\n",
    "    print(f\"ERROR: Label column '{label_col}' not found in CRLM data.\")\n",
    "    print(f\"Available columns: {list(crlm_data.columns)}\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Prepare labels (map to binary, consistent with training)\n",
    "y_crlm_raw = crlm_data[label_col]\n",
    "print(\"Original label distribution:\")\n",
    "print(y_crlm_raw.value_counts())\n",
    "\n",
    "# Map labels: metastasis -> 1, else 0\n",
    "y_crlm = y_crlm_raw.apply(lambda x: 1 if 'metastasis' in str(x).lower() else 0)\n",
    "print(\"\\nEncoded label distribution:\")\n",
    "print(y_crlm.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Prepare feature matrix ---\n",
    "print(\"\\n--- Step 4: Prepare feature matrix ---\")\n",
    "\n",
    "available_genes = [gene for gene in cv_model_genes if gene in crlm_data.columns]\n",
    "missing_genes = [gene for gene in cv_model_genes if gene not in crlm_data.columns]\n",
    "\n",
    "print(f\"Of {len(cv_model_genes)} required model genes:\")\n",
    "print(f\"  - Found in CRLM data: {len(available_genes)} ({len(available_genes)/len(cv_model_genes)*100:.1f}%)\")\n",
    "print(f\"  - Missing: {len(missing_genes)} ({len(missing_genes)/len(cv_model_genes)*100:.1f}%)\")\n",
    "\n",
    "if len(missing_genes) > 0:\n",
    "    print(\"\\nWARNING: Missing genes will be filled with zeros.\")\n",
    "    print(f\"First 10 missing genes: {missing_genes[:10]}\")\n",
    "\n",
    "# Build feature matrix in same column order as used in training\n",
    "X_crlm = pd.DataFrame(index=crlm_data.index, columns=cv_model_genes)\n",
    "\n",
    "# Fill available gene expression\n",
    "X_crlm[available_genes] = crlm_data[available_genes]\n",
    "\n",
    "# Fill missing genes with zeros\n",
    "if missing_genes:\n",
    "    X_crlm[missing_genes] = 0\n",
    "\n",
    "print(f\"Feature matrix built, shape: {X_crlm.shape}\")\n",
    "print(f\"Contains any NA: {X_crlm.isnull().any().any()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe629f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Data formatting for CNN ---\n",
    "print(\"\\n--- Step 5: Data formatting for CNN ---\")\n",
    "\n",
    "# Note: scaling will be applied per-model using each model's scaler\n",
    "X_crlm_cnn_base = X_crlm.to_numpy()\n",
    "X_crlm_cnn = np.expand_dims(X_crlm_cnn_base, axis=-1)\n",
    "print(f\"CNN input shape prepared: {X_crlm_cnn.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681391b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Ensemble predictions using the 5 models ---\n",
    "print(\"\\n--- Step 6: Ensemble prediction with 5 CV models ---\")\n",
    "\n",
    "all_predictions = []\n",
    "for i, (model, scaler) in enumerate(zip(models, scalers)):\n",
    "    # apply scaler corresponding to this model\n",
    "    X_crlm_scaled = scaler.transform(X_crlm)\n",
    "    X_crlm_cnn_scaled = np.expand_dims(X_crlm_scaled, axis=-1)\n",
    "    pred_proba = model.predict(X_crlm_cnn_scaled, verbose=0).flatten()\n",
    "    all_predictions.append(pred_proba)\n",
    "    print(f\"  - Model fold {i+1} prediction completed\")\n",
    "\n",
    "# Average predicted probabilities\n",
    "trs_scores_raw = np.mean(all_predictions, axis=0)\n",
    "print(f\"\\nRaw ensemble score range: [{trs_scores_raw.min():.4f}, {trs_scores_raw.max():.4f}]\")\n",
    "\n",
    "# Apply semantic correction so that higher TRS corresponds to higher metastasis risk\n",
    "trs_scores_final = 1 - trs_scores_raw\n",
    "print(f\"Semantic-corrected TRS range: [{trs_scores_final.min():.4f}, {trs_scores_final.max():.4f}]\")\n",
    "\n",
    "print(\"Ensemble TRS scoring completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Performance evaluation ---\n",
    "print(\"\\n--- Step 7: Evaluate predictive performance ---\")\n",
    "\n",
    "# ROC analysis\n",
    "auc_score = roc_auc_score(y_crlm, trs_scores_final)\n",
    "fpr, tpr, thresholds = roc_curve(y_crlm, trs_scores_final)\n",
    "\n",
    "# Youden index to find optimal threshold\n",
    "youden_scores = tpr - fpr\n",
    "best_threshold_idx = np.argmax(youden_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "\n",
    "# Binary predictions at optimal threshold\n",
    "y_crlm_pred = (trs_scores_final >= best_threshold).astype(int)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_crlm, y_crlm_pred)\n",
    "precision = precision_score(y_crlm, y_crlm_pred)\n",
    "recall = recall_score(y_crlm, y_crlm_pred)\n",
    "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_crlm, y_crlm_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Performance of cross-validated ensemble on CRLM dataset\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AUC: {auc_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 score: {f1_score:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"Optimal threshold: {best_threshold:.4f}\")\n",
    "print(f\"Youden index: {youden_scores[best_threshold_idx]:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=predicted):\")\n",
    "print(\"        Predicted\")\n",
    "print(\"       Primary  Metastasis\")\n",
    "print(f\"True Primary   {tn:3d}      {fp:3d}\")\n",
    "print(f\"True Metastasis{fn:3d}      {tp:3d}\")\n",
    "\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_crlm, y_crlm_pred, target_names=['Primary', 'Metastasis']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c16be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 8: Save predictions and metrics ---\n",
    "print(\"\\n--- Step 8: Save prediction results and performance summary ---\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Sample_ID': X_crlm.index,\n",
    "    'True_Label_str': y_crlm_raw.values,\n",
    "    'True_Label_int': y_crlm.values,\n",
    "    'TRS_Score': trs_scores_final,\n",
    "    'Predicted_Probability': trs_scores_final,\n",
    "    'Predicted_Label_int': y_crlm_pred,\n",
    "    'Predicted_Label_str': ['Metastasis' if pred == 1 else 'Primary' for pred in y_crlm_pred],\n",
    "    'Classification_Correct': (y_crlm == y_crlm_pred).values,\n",
    "})\n",
    "\n",
    "performance_summary = {\n",
    "    'Model_Type': 'Cross_Validation_Ensemble_CNN',\n",
    "    'Validation_Dataset': 'CRLM',\n",
    "    'Total_Samples': len(y_crlm),\n",
    "    'Primary_Samples': int((y_crlm == 0).sum()),\n",
    "    'Metastasis_Samples': int((y_crlm == 1).sum()),\n",
    "    'Features_Used': len(cv_model_genes),\n",
    "    'Available_Features': len(available_genes),\n",
    "    'Missing_Features': len(missing_genes),\n",
    "    'Missing_Feature_Ratio': len(missing_genes) / len(cv_model_genes),\n",
    "    'Performance_Metrics': {\n",
    "        'AUC': float(auc_score),\n",
    "        'Accuracy': float(accuracy),\n",
    "        'Precision': float(precision),\n",
    "        'Recall': float(recall),\n",
    "        'F1_Score': float(f1_score),\n",
    "        'Sensitivity': float(sensitivity),\n",
    "        'Specificity': float(specificity),\n",
    "        'Best_Threshold': float(best_threshold),\n",
    "        'Youden_Index': float(youden_scores[best_threshold_idx])\n",
    "    },\n",
    "    'Confusion_Matrix': {'TN': int(tn), 'FP': int(fp), 'FN': int(fn), 'TP': int(tp)}\n",
    "}\n",
    "\n",
    "summary_file = os.path.join(OUTPUT_DIR, \"crlm_validation_performance_summary.json\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(performance_summary, f, indent=4)\n",
    "print(f\"Performance summary saved: {summary_file}\")\n",
    "\n",
    "print(\"\\nPrediction preview:\")\n",
    "print(results_df[['Sample_ID', 'True_Label_str', 'TRS_Score', 'Predicted_Label_str', 'Classification_Correct']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96810231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 10: Gene correlation with TRS (Pearson) ---\n",
    "print(\"\\n--- Step 10: Compute gene correlations with TRS (Pearson r and p-value) ---\")\n",
    "\n",
    "correlations = []\n",
    "for gene in X_crlm.columns:\n",
    "    try:\n",
    "        corr, p_value = pearsonr(X_crlm[gene].astype(float), trs_scores_final)\n",
    "    except Exception:\n",
    "        corr, p_value = (np.nan, np.nan)\n",
    "    correlations.append((gene, corr, p_value))\n",
    "\n",
    "corr_df = pd.DataFrame(correlations, columns=['Gene', 'Correlation', 'P_Value'])\n",
    "corr_df.dropna(inplace=True)\n",
    "\n",
    "print(f\"Gene correlation calculation completed: {len(corr_df)} genes analyzed.\")\n",
    "print(\"Top 5 positively correlated genes:\")\n",
    "print(corr_df.sort_values('Correlation', ascending=False).head())\n",
    "print(\"\\nTop 5 negatively correlated genes:\")\n",
    "print(corr_df.sort_values('Correlation', ascending=True).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e27206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Top50 gene correlation visualization (25 pos + 25 neg) ---\n",
    "print(\"\\nGenerating gene-correlation visualization...\")\n",
    "\n",
    "top_pos_corr = corr_df.sort_values('Correlation', ascending=False).head(25)\n",
    "top_neg_corr = corr_df.sort_values('Correlation', ascending=True).head(25)\n",
    "top_genes_vis = pd.concat([top_pos_corr, top_neg_corr]).sort_values('Correlation')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Red = risk gene, Blue = protective gene\n",
    "colors = ['#c23616' if c > 0 else '#192a56' for c in top_genes_vis['Correlation']]\n",
    "ax.barh(top_genes_vis['Gene'], top_genes_vis['Correlation'], color=colors)\n",
    "\n",
    "ax.set_xlabel('Pearson Correlation with TRS (Metastasis Risk Score)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Gene', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Top 50 Genes Most Correlated with TRS\\nRed=Risk gene, Blue=Protective gene\\nHigher TRS = Higher mCRC Risk', fontsize=15, fontweight='bold', pad=20)\n",
    "ax.tick_params(axis='y', labelsize=11)\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ebd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add numeric labels\n",
    "for i, (value, name) in enumerate(zip(top_genes_vis['Correlation'], top_genes_vis['Gene'])):\n",
    "    ax.text(value + 0.01 if value > 0 else value - 0.01, i, f'{value:.3f}',\n",
    "            ha='left' if value > 0 else 'right',\n",
    "            va='center',\n",
    "            fontweight='medium',\n",
    "            fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "CORRELATION_PLOT_FILE = os.path.join(OUTPUT_DIR, \"top50_gene_correlations.png\")\n",
    "plt.savefig(CORRELATION_PLOT_FILE, dpi=300, bbox_inches='tight')\n",
    "print(f\"Correlation plot saved to: {CORRELATION_PLOT_FILE}\")\n",
    "plt.show()\n",
    "\n",
    "corr_table_file = os.path.join(OUTPUT_DIR, \"trs_gene_correlation in CRLM Samples.csv\")\n",
    "corr_df.to_csv(corr_table_file, index=False)\n",
    "print(f\"All gene correlations table saved to: {corr_table_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 11: Summary and completion ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 External validation of CV-ensemble model on CRLM dataset completed!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nKey results summary:\")\n",
    "print(f\"• Validation dataset: CRLM ({len(y_crlm)} samples)\")\n",
    "print(f\"• Model type: Cross-validated ensemble CNN\")\n",
    "print(\"• Main performance metrics:\")\n",
    "print(f\"  - AUC: {auc_score:.3f}\")\n",
    "print(f\"  - Accuracy: {accuracy:.3f}\")\n",
    "print(f\"  - Sensitivity: {sensitivity:.3f}\")\n",
    "print(f\"  - Specificity: {specificity:.3f}\")\n",
    "\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"• Prediction results: {os.path.basename(results_file)}\")\n",
    "print(f\"• Performance summary: {os.path.basename(summary_file)}\")\n",
    "print(f\"• Gene correlations table: {os.path.basename(corr_table_file)}\")\n",
    "print(f\"• Top50 correlation plot: {os.path.basename(CORRELATION_PLOT_FILE)}\")\n",
    "\n",
    "print(f\"\\nAll outputs are saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\nModel assessment:\")\n",
    "if auc_score > 0.8:\n",
    "    print(\"✅ Excellent: AUC > 0.8, strong discriminative ability.\")\n",
    "elif auc_score > 0.7:\n",
    "    print(\"✅ Good: AUC > 0.7, reasonable discriminative ability.\")\n",
    "elif auc_score > 0.6:\n",
    "    print(\"⚠️ Moderate: AUC > 0.6, limited discriminative ability.\")\n",
    "else:\n",
    "    print(\"❌ Poor: AUC ≤ 0.6, limited discriminative ability.\")\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
